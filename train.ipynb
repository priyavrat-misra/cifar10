{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import device, get_num_correct, RunBuilder\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# covertes to tensor and normalizes the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "source": [
    "Before starting the training procedure, it is a best practice to try and overfit a single batch of data, so to confirm that the network is implemented correctly and it has the capability to be used as the model for training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:  0 loss:2.3195 acc:0.0938\n",
      "epoch:  1 loss:4.9806 acc:0.1562\n",
      "epoch:  2 loss:6.4253 acc:0.1562\n",
      "epoch:  3 loss:6.3442 acc:0.0938\n",
      "epoch:  4 loss:4.6450 acc:0.1250\n",
      "epoch:  5 loss:3.2097 acc:0.1562\n",
      "epoch:  6 loss:2.4960 acc:0.2500\n",
      "epoch:  7 loss:2.2880 acc:0.1250\n",
      "epoch:  8 loss:2.1752 acc:0.2188\n",
      "epoch:  9 loss:2.1317 acc:0.0938\n",
      "epoch: 10 loss:2.0971 acc:0.2500\n",
      "epoch: 11 loss:2.0512 acc:0.2812\n",
      "epoch: 12 loss:1.9756 acc:0.2500\n",
      "epoch: 13 loss:1.8806 acc:0.3125\n",
      "epoch: 14 loss:1.7805 acc:0.3438\n",
      "epoch: 15 loss:1.6941 acc:0.3750\n",
      "epoch: 16 loss:1.6683 acc:0.3750\n",
      "epoch: 17 loss:1.5856 acc:0.4688\n",
      "epoch: 18 loss:1.4691 acc:0.4375\n",
      "epoch: 19 loss:1.6006 acc:0.4375\n",
      "epoch: 20 loss:1.3912 acc:0.5000\n",
      "epoch: 21 loss:1.3030 acc:0.5000\n",
      "epoch: 22 loss:1.5074 acc:0.4062\n",
      "epoch: 23 loss:1.4688 acc:0.4062\n",
      "epoch: 24 loss:1.4631 acc:0.5625\n",
      "epoch: 25 loss:1.1601 acc:0.5938\n",
      "epoch: 26 loss:1.1292 acc:0.5625\n",
      "epoch: 27 loss:1.2183 acc:0.4688\n",
      "epoch: 28 loss:0.9641 acc:0.6250\n",
      "epoch: 29 loss:1.0707 acc:0.5625\n",
      "epoch: 30 loss:0.9204 acc:0.7188\n",
      "epoch: 31 loss:0.7411 acc:0.7188\n",
      "epoch: 32 loss:0.7713 acc:0.6875\n",
      "epoch: 33 loss:0.6381 acc:0.7812\n",
      "epoch: 34 loss:0.6678 acc:0.7188\n",
      "epoch: 35 loss:0.6333 acc:0.8125\n",
      "epoch: 36 loss:0.6635 acc:0.6875\n",
      "epoch: 37 loss:0.6382 acc:0.7812\n",
      "epoch: 38 loss:0.5243 acc:0.8438\n",
      "epoch: 39 loss:0.4747 acc:0.8438\n",
      "epoch: 40 loss:0.4859 acc:0.7812\n",
      "epoch: 41 loss:0.3200 acc:0.9375\n",
      "epoch: 42 loss:0.2348 acc:0.9688\n",
      "epoch: 43 loss:0.4590 acc:0.7812\n",
      "epoch: 44 loss:0.2751 acc:0.8750\n",
      "epoch: 45 loss:0.4050 acc:0.8750\n",
      "epoch: 46 loss:0.1306 acc:0.9688\n",
      "epoch: 47 loss:0.4368 acc:0.8438\n",
      "epoch: 48 loss:0.2499 acc:0.9062\n",
      "epoch: 49 loss:0.2313 acc:0.9375\n"
     ]
    }
   ],
   "source": [
    "# load the train_set for trying out the model\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=1)\n",
    "\n",
    "model = Network()  # initialize the NN\n",
    "criterion = nn.CrossEntropyLoss()  # loss function (categorical cross-entropy)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # specify the optimizer\n",
    "images, labels = next(iter(train_loader))  # load one batch of train_set\n",
    "\n",
    "for epoch in range(50):\n",
    "    correct = 0  # will be used to track the running num correct\n",
    "    preds = model(images)  # forward pass\n",
    "    loss = criterion(preds, labels)  # calculate loss\n",
    "    optimizer.zero_grad()  # clear accumulated gradients from the previous pass\n",
    "    loss.backward()  # backward pass\n",
    "    optimizer.step()  # perform a single optimization step\n",
    "    correct += get_num_correct(preds, labels)  # update running num correct\n",
    "\n",
    "    # print statistics\n",
    "    print(f'epoch: {epoch:2d} loss:{loss.item():2.4f} acc:{(correct/32):2.4f}')"
   ]
  }
 ]
}